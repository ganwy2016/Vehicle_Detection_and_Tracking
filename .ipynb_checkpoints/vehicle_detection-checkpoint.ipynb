{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import scipy.misc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from IPython.display import HTML\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CarDetector:\n",
    "# spatial_size = (16, 16) # Spatial binning dimensions\n",
    "# hist_bins = 16    # Number of histogram bins\n",
    "# spatial_feat = True # Spatial features on or off\n",
    "# hist_feat = True # Histogram features on or off\n",
    "# hog_feat = True # HOG features on or off\n",
    "\n",
    "    def __init__(self, cspace='YUV', spatial_size=(32, 32),\n",
    "                 hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                 pix_per_cell=8, cell_per_block=2, hog_channel=1):\n",
    "        \n",
    "        self.cspace =cspace\n",
    "        self.spatial_size = spatial_size\n",
    "        self.hist_bins = hist_bins\n",
    "        self.hist_range=hist_range\n",
    "        self.orient = orient\n",
    "        self.pix_per_cell=pix_per_cell\n",
    "        self.cell_per_block=cell_per_block\n",
    "        self.hog_channel=hog_channel\n",
    "        self.vis=False\n",
    "        self.feature_vec=True\n",
    "        self.classifier = []\n",
    "        self.scaler = []\n",
    "        \n",
    "    def get_classifier(self):\n",
    "        return self.classifier\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler\n",
    "\n",
    "    def train_classifier(self,cars,notcars):\n",
    "        classifier_file = 'classifier.pkl'\n",
    "        scaler_file = 'scaler.pkl'\n",
    "        # extract features from dataset\n",
    "        car_features = car_detector.extract_features(cars)\n",
    "        print(\"Car features extracted\")\n",
    "        notcar_features = car_detector.extract_features(notcars)\n",
    "        print(\"Other features extracted\")# Create an array stack of feature vectors\n",
    "        X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "        # Fit a per-column scaler\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "        print(\"X_scaler ready\")\n",
    "        #save the model\n",
    "        joblib.dump(X_scaler, scaler_file)\n",
    "        # Apply the scaler to X - normalise data\n",
    "        scaled_X = X_scaler.transform(X)\n",
    "        print(\"Data normalised\")\n",
    "        # Define the labels vector\n",
    "        y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "        # Split up data into randomized training and test sets\n",
    "        rand_state = np.random.randint(0, 100)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "        # Use a linear SVC \n",
    "        svc = LinearSVC()\n",
    "        # Check the training time for the SVC\n",
    "        t=time.time()\n",
    "        svc.fit(X_train, y_train)\n",
    "        t2 = time.time()\n",
    "        print(t2-t, 'Seconds to train SVC...')\n",
    "        # Check the score of the SVC\n",
    "        print('Train Accuracy of SVC = ', svc.score(X_train, y_train))\n",
    "        print('Test Accuracy of SVC = ', svc.score(X_test, y_test))\n",
    "        # Check the prediction time for a single sample\n",
    "        t=time.time()\n",
    "        prediction = svc.predict(X_test[0].reshape(1, -1))\n",
    "        print(\"prediction\",prediction)\n",
    "        t2 = time.time()\n",
    "        print(t2-t, 'Seconds to predict with SVC')\n",
    "        print(svc)\n",
    "        # save the model\n",
    "        joblib.dump(svc, classifier_file)\n",
    "        self.classifier = svc\n",
    "        self.scaler = X_scaler\n",
    "        print(\"Model saved as:\",classifier_file,\" and \", scaler_file)\n",
    "    \n",
    "    def load_classifier(self,classifier_file,scaler_file):\n",
    "        self.classifier = joblib.load(classifier_file)\n",
    "        self.scaler = joblib.load(scaler_file)\n",
    "        print(\"Model loaded: \\n\\n\",self.classifier)\n",
    "    \n",
    "    # Define a function to compute binned color features  \n",
    "    def bin_spatial(self, img):\n",
    "        # Use cv2.resize().ravel() to create the feature vector\n",
    "        features = cv2.resize(img,self.spatial_size).ravel() \n",
    "        # Return the feature vector\n",
    "        return features\n",
    "    \n",
    "    # Define a function to compute color histogram features  \n",
    "    def color_hist(self,img):\n",
    "        # Compute the histogram of the color channels separately\n",
    "        channel1_hist = np.histogram(img[:,:,0], bins=self.hist_bins, range=self.hist_range)\n",
    "        channel2_hist = np.histogram(img[:,:,1], bins=self.hist_bins, range=self.hist_range)\n",
    "        channel3_hist = np.histogram(img[:,:,2], bins=self.hist_bins, range=self.hist_range)\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "        # Return the individual histograms, bin_centers and feature vector\n",
    "        return hist_features\n",
    "    \n",
    "    # Define a function to return HOG features and visualization\n",
    "    def get_hog_features(self,img):\n",
    "        # Call with two outputs if vis==True\n",
    "        if self.vis == True:\n",
    "            features, hog_image = hog(img, orientations=self.orient, pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                                      cells_per_block=(self.cell_per_block, self.cell_per_block), transform_sqrt=True, \n",
    "                                      visualise=self.vis, feature_vector=self.feature_vec)\n",
    "            return features, hog_image\n",
    "        # Otherwise call with one output\n",
    "        else:      \n",
    "            features = hog(img, orientations=self.orient, pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                           cells_per_block=(self.cell_per_block, self.cell_per_block), transform_sqrt=True, \n",
    "                           visualise=self.vis, feature_vector=self.feature_vec)\n",
    "            return features\n",
    "\n",
    "    def extract_features_img(self, rgb_img):\n",
    "    # apply color conversion if other than 'RGB'\n",
    "        if self.cspace != 'RGB':\n",
    "            if self.cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "            elif self.cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2LUV)\n",
    "            elif self.cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HLS)\n",
    "            elif self.cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2YUV)\n",
    "            elif self.cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: \n",
    "    #             image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert to rgb\n",
    "                feature_image = np.copy(rgb_img)\n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = self.bin_spatial(feature_image)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = self.color_hist(feature_image)\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        hog_features_0 = self.get_hog_features(feature_image[:,:,0])\n",
    "#         hog_features_1 = get_hog_features(feature_image[:,:,1], self.orient, \n",
    "#                         self.pix_per_cell, self.cell_per_block, vis=False, feature_vec=True)\n",
    "#         hog_features_2 = get_hog_features(feature_image[:,:,2], self.orient, \n",
    "#                         self.pix_per_cell, self.cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        features= np.concatenate((spatial_features, hist_features, hog_features_0))#,hog_features_1, hog_features_2))\n",
    "        return features\n",
    "            \n",
    "    # Define a function to extract features from a list of images\n",
    "    # Have this function call bin_spatial() and color_hist()\n",
    "    # this function combines color, histogram and hog features extraction\n",
    "    def extract_features(self,img_files):\n",
    "        # Create a list to append feature vectors to\n",
    "        features = []\n",
    "        # Iterate through the list of images\n",
    "        for file in img_files:\n",
    "            # Read in each one by one\n",
    "#             rgb_img = mpimg.imread(file)\n",
    "            rgb_img = scipy.misc.imread(file)\n",
    "    #         image = cv2.imread(file) # reads a file into bgr values 0-255\n",
    "            features.append(self.extract_features_img(rgb_img))\n",
    "        \n",
    "        # Return list of feature vectors\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    cars = []\n",
    "    notcars = []\n",
    "\n",
    "    # load vehicle images\n",
    "    images = glob.iglob('vehicles/*/*.png', recursive=True)\n",
    "    for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "    # load non vehicle images\n",
    "    images = glob.iglob('non-vehicles/*/*.png', recursive=True)\n",
    "    for image in images:\n",
    "        notcars.append(image)\n",
    "\n",
    "    print('cars = ',len(cars))\n",
    "    print('notcars = ',len(notcars))\n",
    "    return cars,notcars\n",
    "\n",
    "def peak_data(cars, notcars):\n",
    "    data_info = data_look(cars, notcars)\n",
    "    print('Your function returned a count of', \n",
    "          data_info[\"n_cars\"], ' cars and', \n",
    "          data_info[\"n_notcars\"], ' non-cars')\n",
    "    print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "          data_info[\"data_type\"])\n",
    "    # Just for fun choose random car / not-car indices and plot example images   \n",
    "    car_ind = np.random.randint(0, len(cars))\n",
    "    notcar_ind = np.random.randint(0, len(notcars))\n",
    "\n",
    "    # Read in car / not-car images\n",
    "    car_image = mpimg.imread(cars[car_ind])\n",
    "    notcar_image = mpimg.imread(notcars[notcar_ind])\n",
    "\n",
    "    # Plot the examples\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(car_image)\n",
    "    plt.title('Example Car Image')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(notcar_image)\n",
    "    plt.title('Example Not-car Image')\n",
    "    plt.show()\n",
    "\n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "\n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5),max_y=780):\n",
    "    height, width, channels = img.shape\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = int(xs*nx_pix_per_step + x_start_stop[0])\n",
    "            endx = int(startx + xy_window[0])\n",
    "            starty = int(ys*ny_pix_per_step + y_start_stop[0])\n",
    "            endy = int(starty + xy_window[1])\n",
    "            # Append window position to list\n",
    "            if endy<height and endx < width and endy<max_y:\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "    \n",
    "# create a list of rectangles with different sizes across the lower part of the image for searching cars\n",
    "def create_list_rectangles(img):\n",
    "\n",
    "    height, width, channels = img.shape\n",
    "    window_list=();\n",
    "    rectangles = []\n",
    "\n",
    "    step_h = 32\n",
    "    start_h = step_h#int(height/4)\n",
    "    stop_h = height \n",
    "    size_of_sq = int(256 * (1/height))\n",
    "    y_val = int(9*height/16) \n",
    "\n",
    "#     size_vec = [64, 96, 128, 160]\n",
    "#     overlap_vec = [0, 0.5, 0.65, 0.8]\n",
    "    size_vec = [128, 160, 192, 224]\n",
    "    overlap_vec = [0.5, 0.5, 0.5, 0.5]\n",
    "    for i in range(len(size_vec)):\n",
    "        size = size_vec[i]\n",
    "        overlap = overlap_vec[i]\n",
    "        window_list = slide_window(img, x_start_stop=[0, width+size], y_start_stop=[y_val,y_val+4*size], \n",
    "                        xy_window=(size, size), xy_overlap=(overlap,overlap),max_y=height*0.9)\n",
    "        rectangles.extend(window_list)\n",
    "    return rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train or Load existing Model \n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars =  0\n",
      "notcars =  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9e9fa6fbfb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnotcars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpeak_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnotcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcar_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnotcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-649edc3cd900>\u001b[0m in \u001b[0;36mpeak_data\u001b[0;34m(cars, notcars)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpeak_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdata_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_look\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     print('Your function returned a count of', \n\u001b[1;32m     22\u001b[0m           \u001b[0mdata_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_cars\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' cars and'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-649edc3cd900>\u001b[0m in \u001b[0;36mdata_look\u001b[0;34m(car_list, notcar_list)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_notcars\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotcar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Read in a test image, either car or notcar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mexample_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Define a key \"image_shape\" and store the test image shape 3-tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_shape\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "new_model = False\n",
    "new_model = True\n",
    "\n",
    "# create a CarDetector object\n",
    "car_detector = CarDetector()\n",
    "#cspace='RGB', spatial_size=(16, 16),hist_bins=16,hog_channel=0) #cspace='YUV',hog_channel=1) # Options: RGB, HSV, LUV, HLS, YUV \n",
    "        \n",
    "if (new_model):\n",
    "    # load the dataset\n",
    "    cars,notcars = load_dataset()\n",
    "    peak_data(cars,notcars)\n",
    "    #train the classifier\n",
    "    car_detector.train_classifier(cars,notcars)\n",
    "else:\n",
    "    # load existing model\n",
    "    car_detector = CarDetector()\n",
    "    car_detector.load_classifier('classifier.pkl','scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RGB test accuracy = 0.9788 and low number of false positives in test images\n",
    "# HSV test accuracy = 0.9777 but lots of false positives\n",
    "# HLS test accuracy = 0.9688 but lots of false positives\n",
    "# LUV test accuracy = 0.984  but lots of false positives\n",
    "# YUV test accuracy = 0.9786 but lots of false positives  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_rectangles(img,window_list,color= (255,255,255)):\n",
    "    labeled_img = img.copy()\n",
    "    for window in window_list:\n",
    "        pt1 = window[0]\n",
    "        pt2 = window[1]\n",
    "        thickness = 4\n",
    "        cv2.rectangle(labeled_img, pt1, pt2, color, thickness)\n",
    "    return labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the heat map\n",
    "def get_heat_map(img,rectangles,car_detector):\n",
    "    \n",
    "    heat_increment = 20\n",
    "    CV_FILLED = -1\n",
    "    heat_map = np.zeros_like(img)\n",
    "    \n",
    "    for rectangle in rectangles:\n",
    "        heat_img = np.zeros_like(img)\n",
    "        pt1 = rectangle[0]\n",
    "        pt2 = rectangle[1]\n",
    "        crop_img = img[pt1[1]:pt2[1], pt1[0]:pt2[0]]\n",
    "        size = (64,64)\n",
    "        crop_img = cv2.resize(crop_img, size)#.astype(np.float64)\n",
    "        \n",
    "        img_features = car_detector.extract_features_img(crop_img)\n",
    "\n",
    "        features = np.vstack((img_features)).astype(np.float64)\n",
    "        features = np.array(features).reshape(1, -1)\n",
    "        \n",
    "        feature_scaler = car_detector.get_scaler()\n",
    "        classifier = car_detector.get_classifier()\n",
    "        \n",
    "        scaled_features = feature_scaler.transform(features)\n",
    "        prediction = classifier.predict(scaled_features.reshape(1, -1))\n",
    "        \n",
    "        if prediction == 1:\n",
    "            cv2.rectangle(heat_img, pt1, pt2, color=(heat_increment,0,0), thickness=CV_FILLED)\n",
    "            heat_map = cv2.add(heat_map, heat_img)\n",
    "            \n",
    "    return heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply filter to the heat_map\n",
    "# Note: th_ratio should be a ratio (0-1)\n",
    "# It will be used with respect to the maximum pixel value in the image\n",
    "def filter_heat_map(heat_map, th_ratio=0.5):\n",
    "    red_channel = np.copy(heat_map[:,:,0])\n",
    "#     print(\"max:\",np.amax(red_channel))\n",
    "    th = np.amax(red_channel)*th_ratio # define threshold\n",
    "#     print(\"th:\",th)\n",
    "    filt_heat_map = np.zeros_like(heat_map)\n",
    "    if np.amax(red_channel)>0:\n",
    "        red_channel[red_channel>=th]=255\n",
    "        red_channel[red_channel<th]=0\n",
    "        filt_heat_map[:,:,0]=red_channel\n",
    "    return filt_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# computes positions and bounding rectangles identifying the location of detected vehicles\n",
    "def get_detected(heat_map,area_th = 20):\n",
    "     # define a threshold for minimum area required to be a positive detection\n",
    "    imgray = heat_map[:,:,0]#cv2.cvtColor(heat_map,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(imgray.astype(np.uint8),130,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     im2, contours, hierarchy = cv2.findContours(heat_map[:,:,0],cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detected_car_pos = [];\n",
    "    detected_car_rectangles = [];\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "#         print(area)\n",
    "        if area>area_th:\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate image centroid\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            pt1 = (x,y)\n",
    "            pt2 = (x+w,y+h)\n",
    "            detected_car_pos.append([cx,cy])\n",
    "            detected_car_rectangles.append([pt1,pt2])\n",
    "    return detected_car_pos,detected_car_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img,debug=0):\n",
    "    \n",
    "    if not hasattr(process_image, \"heat_map_old\"):\n",
    "        process_image.heat_map_old = np.zeros_like(img)\n",
    "    \n",
    "    if not process_image.heat_map_old.size:\n",
    "        process_image.heat_map_old = np.zeros_like(img)\n",
    "    \n",
    "    decay = 0.2\n",
    "    # apply decay to the heat_map\n",
    "    process_image.heat_map_old = process_image.heat_map_old*(1-decay)\n",
    "    \n",
    "#     rectangles = create_list_rectangles(img)\n",
    "\n",
    "    heat_map = get_heat_map(img,process_image.rectangles,process_image.car_detector)\n",
    "    \n",
    "    filtered_heat_map = filter_heat_map(heat_map,th_ratio=0.1)\n",
    "    \n",
    "    process_image.heat_map_old = (filtered_heat_map*0.5 + process_image.heat_map_old*0.5)\n",
    "\n",
    "    detected_car_pos,detected_car_rectangles = get_detected(process_image.heat_map_old,area_th = 1000)\n",
    "    \n",
    "    detected_cars_img = draw_rectangles(img,detected_car_rectangles,color= (255,255,255))\n",
    "    if debug:\n",
    "        # Ploting images\n",
    "        labeled_img = draw_rectangles(img,process_image.rectangles)\n",
    "\n",
    "        fig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(24, 9))\n",
    "        fig.tight_layout();\n",
    "        \n",
    "\n",
    "        ax1.imshow(heat_map)\n",
    "        ax1.set_title('Heat map')\n",
    "        ax2.imshow(filtered_heat_map.astype(np.uint8))\n",
    "        ax2.set_title('Filtered heat_map')\n",
    "        ax3.imshow(process_image.heat_map_old.astype(np.uint8))\n",
    "        ax3.set_title('Used heat_map')\n",
    "        ax4.imshow(img)\n",
    "        ax4.set_title('Source image')\n",
    "        ax5.imshow(labeled_img)\n",
    "        ax5.set_title('Positive cars')\n",
    "        ax6.imshow(detected_cars_img)\n",
    "        ax6.set_title('Confirmed cars')\n",
    "        ax1.axis('off');\n",
    "        ax2.axis('off');\n",
    "        ax3.axis('off');\n",
    "        ax4.axis('off');\n",
    "        ax5.axis('off');\n",
    "        ax6.axis('off');\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.);\n",
    "        plt.show();\n",
    "        \n",
    "    return detected_cars_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'test_images/test_06.jpg' # two cars, black and white\n",
    "file = 'test_images/test_05.jpg' # two cars, black and white\n",
    "file = 'test_images/test_04.jpg' # two cars, black and white\n",
    "file = 'test_images/test_03.jpg' # white car\n",
    "file = 'test_images/test_02.jpg' # no cars\n",
    "file = 'test_images/test_01.jpg' # two cars, black and white\n",
    "\n",
    "rgb_img = scipy.misc.imread(file)\n",
    "# img = mpimg.imread(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reset heat_map_old\n",
    "process_image.heat_map_old=np.zeros_like(rgb_img)\n",
    "process_image.car_detector = car_detector\n",
    "process_image.rectangles = create_list_rectangles(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,4932) (2580,) (1,4932) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3812ae252789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-645f2d71003d>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(img, debug)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     rectangles = create_list_rectangles(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mheat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_heat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar_detector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfiltered_heat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_heat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheat_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-0da7553aa31e>\u001b[0m in \u001b[0;36mget_heat_map\u001b[0;34m(img, rectangles, car_detector)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcar_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/npereira/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,4932) (2580,) (1,4932) "
     ]
    }
   ],
   "source": [
    "process_image(rgb_img,debug=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_output.mp4\n",
      "[MoviePy] Writing video project_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [19:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_output.mp4 \n",
      "\n",
      "CPU times: user 19min 49s, sys: 1.99 s, total: 19min 51s\n",
      "Wall time: 19min 1s\n",
      "Finished processing video file\n"
     ]
    }
   ],
   "source": [
    "video_output = 'project_output.mp4';\n",
    "clip1 = VideoFileClip(\"project_video.mp4\");\n",
    "video_clip = clip1.fl_image(process_image); #NOTE: this function expects color images!!\n",
    "%time video_clip.write_videofile(video_output, audio=False);\n",
    "print('Finished processing video file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
